# 『新しいLinuxの教科書』
- ユーザーログイン時に自動でシェルを起動する。これをログインシェルと呼ぶ
- ユーザーがキーボードと画面を利用して直接シェルを操作する対話型操作に対して一連の操作の流れを記述したファイルのことをシェルスクリプトと呼ぶ
- curlコマンド
    - URLを使用してデータの転送を行うためのコマンドラインツール
    - `curl https://example.com`を実行すると、`https://example.com`からHTMLファイルが返される
    - `-X`オプションは、curlコマンドで使用される。HTTPメソッドを指定
- エイリアス
    - 分かりやすい別名を与えてコマンドを使いやすくする為の機能
- bashの設定ファイル
    - シェルの設定を行っても終了すると設定は全て消える
    - 次回以降にログイン時に同じ設定にするにはbashの設定ファイルを記述する必要がある
    - ログインシェルとして起動される際に読み込む設定ファイルの一つに~/.bashrcがある
    - ~/.bashrcファイルを修正した後にログインしなおすのが面倒な場合はsourceコマンドを使用することで設定を即座に反映
- コマンドを探す
    - catコマンドは/binディレクトリの下に/bin/catというファイルがある
    - /bin/catと入力しなくてもcatと入力するだけで実行できるのは$PATHという環境変数に設定された場所から自動的にコマンドを探すから
    - パスがあるおかげでコマンドが実際にどこにあるのかを意識せずにコマンド名だけを入力すれば実行できるようになっている
- シェル変数
    - bash内部で使用する変数
    - 設定した変数は先頭に$記号を付けて`$<変数名>`という形で参照できる
- シェルスクリプト
    - シバン
        - スクリプトがどのプログラムで実行されるべきかを明示的に指定する
        - bashを使用する場合、次のように指定`#!/bin/bash`
    - sourceコマンド
        - 指定したファイルの内容をそのままコマンドラインに入力したときと同じように実行
        - sourceコマンドは対象ファイルを直接実行するわけではないためファイルに実行権限は不要
        - ドットコマンドはsourceコマンドと同じ
# 『Amazon Web Services基礎からのネットワーク＆サーバー』
- IPアドレスは前半の部分を「ネットワーク部」、後半の部分を「ホスト部」という
    - ネットワーク部は同じネットワークに属する限り同じ値
    - ホスト部は割り当てたいサーバーやクライアント、ネットワーク機器に対する連番
- 「192.168.1.0～192.168.1.255」や「192.168.255.255」といった表現は長いため、通常IPアドレス範囲を示すときには「CIDR(サイダー)表記」もしくは「サブネット表記」のいずれかの表記を使う
    - CIDR表記
        - ネットワーク部のビット長を「/ビット長」で示す。このビット長のことをプレフィックスという
        - 「192.168.0.0～192.168.255.255」は「192.168.0.0/16」と記述
    - サブネットマスク表記
        - プレフィックスのビット数だけ2進数の1を並べ、残りは0を記述
        - 「192.168.0.0～192.168.255.255」は「192.168.0.0/255.255.0.0」と記述
- ネットワークにデータを流すためにはルーティング情報と呼ばれる設定が必要でこの設定はAWSではルートテーブルと呼ばれる
- 「0.0.0.0/0」は全てのIPアドレス範囲を示しておりこのデフォルトの転送先をデフォルトゲートウェイ(宛先が未知のIPアドレスだった際に、パケットを転送)と呼ぶ
`$sudo dnf -y install httpd`
- dnfコマンドはアプリをダウンロードしてインストールしたり、アンインストールしたりするときに用いる管理者コマンド。yumコマンドの後継。
- -yオプションはユーザーの確認無しにすぐインストールする指定
`$sudo systemctl enable httpd.service`
- systemctlコマンドは指定したコマンドを起動、停止、再起動するコマンド
- enableは自動起動するコマンド
`$sudo systemctl list-unit-files -t service`
- list-unit-filesは設定の確認
- -tはタイプの指定を行うオプション。
- serviceはサービスに関するユニットファイルを表示するための具体的なタイプ
`$ps -ax`
- -xはほかの端末に結び付けられているプロセスも表示。
- -axオプションを指定するとサーバー上で動作しているすべてのプロセスが表示
`$ps -ax | grep httpd`
- 上記ではhttpdを含む行だけを出力できる
`$sudo lsof -i -n -p`
- lsof(List Open Files)はプロセスが開いているファイルやネットワーク接続などを表示するためのコマンド。
- -iはネットワークに関する情報を表示するオプション。
- -nはネットワークアドレスやポートなどの数値を数値として表示するオプション
- -pは特定のプロセスの情報を表示するためのオプション。この後にプロセスID（PID）を指定
- IPアドレス→DNS名、DNS→IPアドレスの変換はnslookupコマンドまたはdigコマンドを使用する
- サーバーとの疎通確認でpingコマンドを使用するが、pingコマンドのプロトコルはICMP。AWSのデフォルトのセキュリティグループの構成ではICMPプロトコルは許可されていない
# 『仕組みと使い方がわかる Docker&Kubernetesのきほんのきほん』
## Docker
- イメージからコンテナを作成して利用するだけでなく、コンテナからもイメージが作れる
- コンテナを破棄するためには停止する必要がある
- コンテナを削除してもイメージは残る
- ボリュームマウントはDocker Engineが管理している領域内にボリュームを作成し、ディスクとしてコンテナにマウント
- バインドマウントはDockerをインストールしたPCのドキュメントやデスクトップなどDocker Engineの管理していない場所の既に存在するディレクトリをコンテナにマウント
- イメージの作成方法は既にあるコンテナをcommitでイメージの書き出しをする方法とDockerfileでイメージを作る方法
- 既にあるコンテナを複製したい移動したいなどの用途に使用
- bashを動かすとコンテナ内のMySQLやApacheなどの他のソフトは動かない
- Docker Composeはネットワークやボリュームも合わせて作成できるが、Dockerfileはイメージを作るものなのでネットワークやボリュームを作成できない
- Kubernetesはコンテナを管理するものでDocker Composeはコンテナを作って消すもの
- 定義ファイルは1つのフォルダに対して1つしか配置できない
- docker-compose.ymlのYAML形式はスペースに意味がある言語なのでタブでは意味を持たない。半角スペース2つと最初に決めたらその後も2つずつ増やす必要がある
## Kubernetes
- KubernetesはDockerとは別のソフトで複数の物理的マシンに複数のコンテナがあることが前提。20個のコンテナを作ろうとすると20回docker runコマンドが必要で、物理マシンが複数に分かれているとDocker Composeを使用しても個々のマシンに接続する面倒な作業がある。障害が起こった際やコンテナをアップデートする度に作業が増えるのでKubernetesはこのような煩雑さを取り除くツール
- マスターノードではコンテナは動いていない
- マスターとワーカーで構成されたKubernetesシステムの一群をクラスターという
- マスターノード、ワーカーノード共にKubernetesとCNI(仮想ネットワークのドライバ)が必要
- マスターノードにはコンテナなどの状態管理のためにetcdというデータベースを入れる。また、マスターノードの設定を行うためにkubectlを入れる
- ワーカーノードにはDocker Engineなどのコンテナエンジンを入れる
- ワーカーノードでは、kube-letとkube-proxyが動く
    - kube-let
        - マスターノードと連携してワーカーノード上にPodを配置し実行、定期的に監視し、通知する
    - kube-proxy
        - ネットワーク通信をルーティングする仕組み
- Kubernetesは常に望ましい状態に保つ
- Pod
    - コンテナとボリュームがセットになったもの
    - 1Podに1コンテナだがコンテナは複数にすることも可能
- サービス
    - Podをまとめて管理するもの
    - Podが複数のワーカーノード(物理的マシン)上に存在している場合でも一つのサービスとして管理する
    - 役割はロードバランサー(負荷分散装置)
    - サービスごとに自動で固定のIPアドレスが振られる
- レプリカセット
    - アクセスを管理することに対してレプリカセットはPodの数を管理する。障害でPodが停止した際に増やしたり、定義ファイルのPodの数が減った際に減らしたりする
- Podはサービスとレプリカセットで管理されている
- レプリカ
    - レプリカセットにより管理されている同一構成のPodをレプリカと呼ぶ
- デプロイメント
    - Podのデプロイを管理するもの。Podがどのイメージを使うのかなどPodに関する情報を持っている
- Podやサービスに関する設定をマニフェストと呼び、それを記述したファイルをマニフェストファイルと呼ぶ
- 定義ファイルはPodやサービス、デプロイメント、レプリカセットなどのリソース単位で記述
- 例えばApacheのPodを作りたい場合はApacheデプロイメントとApacheサービスの2つのリソースを記述
- ノードはおおよそ物理的なマシン
# 『Kubernetes完全ガイド』
## 第1章 Dockerの復習と「Hello, Kubernetes」
- Kubernetesを利用する際にDockerに関して必ず学んだ方が良い知識
    - Dockerコンテナの設計
        - 不変のインフラを実現するイメージにする。コンテナ起動後に外部から実行バイナリを取得したりパッケージをインストールしたりすると、外部要因によってコンテナイメージの実行結果が変わってしまう。コンテナイメージの中に可能な限り埋め込み普遍的な状態にする。
        - Dockerイメージをなるべく軽量に保つ。aptでパッケージをインストールした後のリポジトリのパッケージリストなどのキャッシュファイル削除。また、ベースイメージが軽量なディストリビューションを利用する。
    - Dockerfileの書き方
    - Dockerイメージのビルド
        - golangのDockerイメージにはGoのコンパイルツールなども含まれているため、作成したイメージにもコンパイルツールが含まれてしまい、イメージのサイズが非常に大きくなってしまう問題がある。この問題はマルチステージビルドを利用することで解決できる。
    - Dockerレジストリへのイメージのプッシュ
## 第2章 なぜKubernetesが必要なのか？
- Docker単体ではホストを複数台協調して動作させたり一元的に管理したりは出来ない。
- Affinity(密接な関係、類似性)
    - Podがどのノードや他のPodと一緒に配置されるべきかを指定する設定。これにより、Podを特定のノードやラベルに基づいて優先的に配置するように指示できる
- Anti-affinity
    - Podが特定のノードや他のPodと一緒に配置されないように制御する設定。これにより、特定の条件下でPodの分散を強制することができる。
- etcd
    - Kubernetesをはじめとする分散システムで使用される分散キーバリューストア。Kubernetesでは、クラスタの状態を保存し、管理する中心的な役割を果たしており、クラスタ全体の構成情報やメタデータを格納している。具体的には、Kubernetesの全てのオブジェクト（Pod、Service、ConfigMapなど）や状態情報（ノードのリソース状況やイベントなど）は、etcdに保存される
## 第3章 Kubernetes環境の選択肢
## 第4章 APIリソースとkubectl
## 第5章 Workloads APIsカテゴリ
## 第6章 Service APIsカテゴリ
## 第7章 Config＆Storage APIsカテゴリ
## 第8章 Cluster APIsカテゴリとMetadata APIsカテゴリ
## 第9章 リソース管理とオートスケーリング
## 第10章 ヘルスチェックとコンテナのライフサイクル
## 第11章 メンテナンスとノードの停止
## 第12章 高度で柔軟なスケジューリング
## 第13章 セキュリティ
## 第14章 マニフェストの汎用化を行うオープンソースソフトウェア
## 第15章 モニタリング
## 第16章 コンテナログの集約
## 第17章 Kubernetes環境でのCI/CD
## 第18章 マイクロサービスアーキテクチャとサービスメッシュ
## 第19章 Kubernetesのアーキテクチャを知る
## 第20章 Kubernetesとこれから

# 『AWSコンテナ設計・構築［本格］入門』
- コンテナのイメージに割り当てるラベルは主にイメージのバージョン管理用途で使用
# Ridgepole
- スキーマ定義を元に既存DBに対して変更SQLを生成/実行するマイグレーションツール
- これにより、データベースのスキーマを追跡し、変更を管理することが容易になる。
- 特に、Ruby on RailsなどのRubyベースのアプリケーションでよく使用されるが、他のプロジェクトでも利用されることがある
# Argo CD
- Kubernetesクラスター向けGitOpsツール
- Argo CDは、Kubernetesのリソース（Deployment、Service、ConfigMapなど）の定義ファイルをGitリポジトリで管理する
- Argo CDは、単に定義ファイルをGitリポジトリで管理するだけでなく、CI/CDの役割も果たす
- テストするアプリケーションのDockerイメージをビルドし、ビルドしたDockerイメージをKubernetesクラスターにデプロイする。デプロイしたアプリケーションに対してリクエストを送信し、期待されるレスポンスが返ってくるかどうかを確認する。
# Helm
- Kubernetesクラスター上でアプリケーションやマイクロサービスのデプロイメントや管理を容易に行うためのパッケージ管理ツール
- Kubernetesリソースのテンプレートや構成をパッケージ化し、再利用可能な形式で提供するものをHelmチャートという
- Argo CDとHelmを組み合わせることは一般的
- Argo CDがHelmチャートの変更を監視し、必要に応じてKubernetesクラスターにデプロイする
# Istio
- Kubernetesのクラスター内でサービスメッシュを構築し、マイクロサービスアプリケーションの通信を管理、保護、監視するためのツール
- サービスメッシュはマイクロサービスアーキテクチャでの通信を制御し、保護し、監視するためのネットワーキングレイヤーの一種。サービスメッシュは、アプリケーション内のすべてのサービス間の通信を抽象化し、管理することが可能
- Istioは単一のアプリケーションに限定されるのではなく、マイクロサービスアーキテクチャを採用した複数のサービスから構成されるアプリケーションに適用される
# GitHub Actions
- ワークフロー Workflow
    - コードの変更に対して自動的に実行される一連の手順やジョブ
- name
    - ワークフローの名前はnameプロパティで指定。
    - name フィールドはユニークであるべき。
    - 同じリポジトリ内で異なるワークフローが同じ name を持つことは避けるべき。
- on
    - GitHub Actionsのワークフロートリガーを定義するために使用される
    - このキーワードは、どのイベントがワークフローを実行するかを指定
    - workflow_dispatchはワークフローを手動でトリガーするためのイベント
- runs-on
    - ジョブがどの種類のランナー環境で実行されるかを指定。ランナー環境(Linux、macOS、Windowsなど)を利用してジョブを実行
    - ランナー環境をWindowsに設定すると、ジョブ内で実行されるコマンドはWindowsのコマンドプロンプト(またはPowerShell)
- Step
    - 実際のコマンドやアクションを実行する単位。シェルコマンド、スクリプト、コマンドラインツールの実行など、特定の処理を指定。nameでステップ名を設定する
- run
    - 指定されたコマンドを実行するために使われる
- checkout
    - リポジトリのコードをワークフローの実行環境にチェックアウト(取得)
- uses
    - GitHub Actionsワークフロー内で利用するアクションを指定するためのキーワード。ある特定のタスクや処理を実行するための再利用可能なコードの塊
- npm ci コマンドは、プロジェクトの package-lock.json ファイルに基づいて依存関係を正確にインストールするためのもの
- needs
    - 複数ジョブがある場合、並行して実行されるが、並行実行しないようにすることもできる。
    - このキーワードを使用することで、特定のジョブが別のジョブの完了を待つように設定できる。例えば、testジョブが失敗した場合、deployジョブを実行しない等。
- コンテキスト
    - `run: echo "${{ toJSON(github) }}"`
    - GitHub Actionsワークフロー内で利用できる特殊な変数のセット。これらの変数には、GitHubリポジトリ、イベント、ユーザーなどの情報が含まれており、ワークフローの実行中に利用できる状態データを提供する
- typesフィルター
    - ワークフローがトリガーされるべきイベントの種類を指定するためにonキーワードの下で使用される。例えば、openedはプルリクエストがオープンされたときに使用される
- paths-ignore
    - ワークフロー自体やその他のワークフロー設定ファイルの変更が行われた場合、ワークフローを再実行することを防ぐ
    - この設定を使用することで、ワークフローが特定のファイルやディレクトリに対する変更に反応するかどうかを制御し、ワークフローの無駄な再実行を避ける
- CIをスキップするためのキーワード
    - `[ci skip]`や`[skip ci]`をコミットメッセージに追加する
- アーティファクト
    - ビルドやテストの結果として生成された重要なファイルやデータのこと
    - これらのファイルは、通常はビルドされたアプリケーション、生成されたドキュメント、テスト結果のレポート、およびデプロイ可能なパッケージなどが含まれる

# 『GitHub CI/CD実践ガイド――持続可能なソフトウェア開発を支えるGitHub Actionsの設計と運用』
## 第1章 ソフトウェア開発とGitHub
- 継続的インテグレーションはコードの変更を頻繫にコードベースへ統合し、正しく動作するかを繰り返し検証する
- 継続的デリバリーはいつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する
## 第2章 GitHub Actionsの基礎概念
自動化できるタスク
- プルリクエストが作成されたら、ビルドとテストを実行する
- リリースタグが作成されたら、コンテナイメージをデプロイする
- Issueが作成されたら、ランダムにメンバーをアサインする
## 第3章 ワークフロー構文の基礎
- コンテキストやデフォルト環境変数から、ワークフロー実行時の情報などが取得できます。コンテキストの参照は、中間環境変数を使うと安全。
## 第4章 継続的インテグレーションの実践

# Argo CD Essential Guide for End Users with Practice
